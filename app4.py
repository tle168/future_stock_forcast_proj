import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from vnstock import * # N·∫°p th∆∞ vi·ªán ƒë·ªÉ s·ª≠ d·ª•ng
from datetime import datetime, timedelta
from ollama_helper import *
from ta.volatility import BollingerBands
from ta.trend import MACD, EMAIndicator, SMAIndicator
from ta.momentum import RSIIndicator
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from model_lstm import prepare_lstm_data, train_lstm_model, forecast_lstm
from ta_signals import compute_indicators, generate_signals, print_signals, predict_stock_price
from charts import plot_price_forecast, plot_heatmap
import io
import requests
import json
# Th∆∞ vi·ªán cho LSTM
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
# C√°c th∆∞ vi·ªán kh√°c
import io
import requests
import json
import openpyxl # C·∫ßn thi·∫øt cho to_excel v·ªõi engine='openpyxl'
# Cho News Fetching (n·∫øu d√πng scraping th·ª±c t·∫ø)
from bs4 import BeautifulSoup

# --- C·∫•u h√¨nh Ollama ---
OLLAMA_HOST = "http://localhost:11434/v1"
OLLAMA_MODEL = "Gemma3"
OLLAMA_API_ENDPOINT = f"{OLLAMA_HOST}/api/generate"

def last_n_days(n):
    """
    Return a date value in YYYY-MM-DD format for last n days. If n = 0, return today's date.
    """
    date_value = (datetime.today() - timedelta(days=n)).strftime('%Y-%m-%d')
    return date_value

LAST_1Y = last_n_days(365)
LAST_30D = last_n_days(30)
LAST_WEEK = last_n_days(7)
YESTERDAY = last_n_days(1) # ng√†y h√¥m qua (kh√¥ng ph·∫£i l√† ng√†y cu·ªëi c√πng giao d·ªãch, ƒë∆°n gi·∫£n l√† ng√†y li·ªÅn tr∆∞·ªõc)
Today = datetime.today().strftime('%Y-%m-%d') # ng√†y h√¥m nay (kh√¥ng ph·∫£i l√† ng√†y cu·ªëi c√πng giao d·ªãch, ƒë∆°n gi·∫£n l√† ng√†y li·ªÅn tr∆∞·ªõc)
# =========================
# X·ª≠ l√Ω d·ªØ li·ªáu v√† LSTM
# =========================

# --- C√°c h√†m ch·ª©c nƒÉng ---

def fetch_stock_data(ticker, source='VCI', days_to_fetch=1000):
    """
    L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ c·ªï phi·∫øu t·ª´ vnstock.
    """
    end_date=Today
    start_date = last_n_days(days_to_fetch)
    # end_date = datetime.now()
    # start_date = end_date - timedelta(days=days_to_fetch)
    try:
        stock = Vnstock().stock(symbol=ticker, source='VCI') # ƒê·ªãnh nghƒ©a bi·∫øn vnstock l∆∞u th√¥ng tin m√£ ch·ª©ng kho√°n & ngu·ªìn d·ªØ li·ªáu b·∫°n s·ª≠ d·ª•ng
        df = stock.quote.history(start=start_date, end=end_date, interval='1D') # Thi·∫øt l·∫≠p Date t·∫£i d·ªØ li·ªáu v√† khung Date tra c·ª©u l√† 1 ng√†y

        # df = vnstock.stock_historical_data(
        #     symbol=ticker,
        #     start_date=start_date.strftime('%Y-%m-%d'),
        #     end_date=end_date.strftime('%Y-%m-%d'),
        #     resolution='1D',
        #     type='stock',
        #     beautify=True,
        #     source=source
        # )
        if df is not None and not df.empty:
            df.columns=['Th·ªùi Gian', 'Open', 'High', 'Low', 'Close', 'Volume']
            if 'Th·ªùi Gian' not in df.columns:
                date_cols = ['time', 'TradingDate', 'Date']
                for col in date_cols:
                    if col in df.columns:
                        df.rename(columns={col: 'Th·ªùi Gian'}, inplace=True)
                        break
            if 'Th·ªùi Gian' not in df.columns:
                st.error(f"Kh√¥ng t√¨m th·∫•y c·ªôt ng√†y th√°ng trong d·ªØ li·ªáu t·ª´ {source} cho {ticker}.")
                return pd.DataFrame()

            df['Th·ªùi Gian'] = pd.to_datetime(df['Th·ªùi Gian'])
            df = df.sort_values(by='Th·ªùi Gian')

            required_cols = {'ƒê√≥ng c·ª≠a': ['Close', 'close'], 'M·ªü c·ª≠a': ['Open', 'open'],
                             'Cao nh·∫•t': ['High', 'high'], 'Th·∫•p nh·∫•t': ['Low', 'low'],
                             'Kh·ªëi l∆∞·ª£ng': ['Volume', 'volume', 'KLGD kh·ªõp l·ªánh']}
            for vn_col, en_cols in required_cols.items():
                if vn_col not in df.columns:
                    for en_col in en_cols:
                        if en_col in df.columns:
                            df.rename(columns={en_col: vn_col}, inplace=True)
                            break
                if vn_col not in df.columns:
                     st.warning(f"Kh√¥ng t√¨m th·∫•y c·ªôt '{vn_col}' trong d·ªØ li·ªáu. M·ªôt s·ªë t√≠nh nƒÉng c√≥ th·ªÉ kh√¥ng ho·∫°t ƒë·ªông.")
            df.reset_index(drop=True, inplace=True)
            return df
        else:
            st.warning(f"Kh√¥ng c√≥ d·ªØ li·ªáu tr·∫£ v·ªÅ t·ª´ {source} cho m√£ {ticker} trong kho·∫£ng th·ªùi gian ƒë√£ ch·ªçn.")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"L·ªói khi l·∫•y d·ªØ li·ªáu t·ª´ {source} cho m√£ {ticker}: {e}")
        return pd.DataFrame()

def calculate_technical_indicators(df):
    """
    T√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t.
    """
    if df.empty or 'ƒê√≥ng c·ª≠a' not in df.columns:
        st.warning("Thi·∫øu c·ªôt 'ƒê√≥ng c·ª≠a' ƒë·ªÉ t√≠nh ch·ªâ b√°o k·ªπ thu·∫≠t.")
        return df.copy()

    df_tech = df.copy()
    df_tech['MA5'] = SMAIndicator(close=df_tech['ƒê√≥ng c·ª≠a'], window=5, fillna=True).sma_indicator()
    df_tech['MA20'] = SMAIndicator(close=df_tech['ƒê√≥ng c·ª≠a'], window=20, fillna=True).sma_indicator()
    df_tech['MA50'] = SMAIndicator(close=df_tech['ƒê√≥ng c·ª≠a'], window=50, fillna=True).sma_indicator()
    df_tech['MA200'] = SMAIndicator(close=df_tech['ƒê√≥ng c·ª≠a'], window=200, fillna=True).sma_indicator()
    df_tech['RSI'] = RSIIndicator(close=df_tech['ƒê√≥ng c·ª≠a'], window=14, fillna=True).rsi()
    macd = MACD(close=df_tech['ƒê√≥ng c·ª≠a'], window_slow=26, window_fast=12, window_sign=9, fillna=True)
    df_tech['MACD_line'] = macd.macd()
    df_tech['MACD_signal'] = macd.macd_signal()
    df_tech['MACD_hist'] = macd.macd_diff()
    bb = BollingerBands(close=df_tech['ƒê√≥ng c·ª≠a'], window=20, window_dev=2, fillna=True)
    df_tech['BB_high'] = bb.bollinger_hband()
    df_tech['BB_low'] = bb.bollinger_lband()
    df_tech['BB_mid'] = bb.bollinger_mavg()
    return df_tech

def generate_signals(df):
    """
    T·∫°o t√≠n hi·ªáu mua/b√°n d·ª±a tr√™n c√°c ch·ªâ b√°o.
    """
    if df.empty:
        return df.copy()
    df_sig = df.copy()
    df_sig['Signal'] = 0
    if 'MA5' in df_sig.columns and 'MA20' in df_sig.columns:
        buy_condition = (df_sig['MA5'] > df_sig['MA20']) & (df_sig['MA5'].shift(1) <= df_sig['MA20'].shift(1))
        sell_condition = (df_sig['MA5'] < df_sig['MA20']) & (df_sig['MA5'].shift(1) >= df_sig['MA20'].shift(1))
        df_sig.loc[buy_condition, 'Signal'] = 1
        df_sig.loc[sell_condition, 'Signal'] = -1
    if 'RSI' in df_sig.columns:
        buy_rsi_condition = (df_sig['RSI'] > 30) & (df_sig['RSI'].shift(1) <= 30)
        sell_rsi_condition = (df_sig['RSI'] < 70) & (df_sig['RSI'].shift(1) >= 70)
        df_sig.loc[buy_rsi_condition & (df_sig['Signal'] == 0), 'Signal'] = 1
        df_sig.loc[sell_rsi_condition & (df_sig['Signal'] == 0), 'Signal'] = -1
    if 'MACD_line' in df_sig.columns and 'MACD_signal' in df_sig.columns:
        buy_macd_condition = (df_sig['MACD_line'] > df_sig['MACD_signal']) & (df_sig['MACD_line'].shift(1) <= df_sig['MACD_signal'].shift(1))
        sell_macd_condition = (df_sig['MACD_line'] < df_sig['MACD_signal']) & (df_sig['MACD_line'].shift(1) >= df_sig['MACD_signal'].shift(1))
        df_sig.loc[buy_macd_condition & (df_sig['Signal'] == 0), 'Signal'] = 1
        df_sig.loc[sell_macd_condition & (df_sig['Signal'] == 0), 'Signal'] = -1
    df_sig['Buy_Signal_Price'] = np.nan
    df_sig['Sell_Signal_Price'] = np.nan
    if 'ƒê√≥ng c·ª≠a' in df_sig.columns:
        df_sig.loc[df_sig['Signal'] == 1, 'Buy_Signal_Price'] = df_sig['ƒê√≥ng c·ª≠a']
        df_sig.loc[df_sig['Signal'] == -1, 'Sell_Signal_Price'] = df_sig['ƒê√≥ng c·ª≠a']
    return df_sig

def plot_market_price(df, ticker):
    """
    V·∫Ω ƒë·ªì th·ªã gi√° ƒë√≥ng c·ª≠a v√† kh·ªëi l∆∞·ª£ng.
    """
    if df.empty or 'Th·ªùi Gian' not in df.columns or 'ƒê√≥ng c·ª≠a' not in df.columns or 'Kh·ªëi l∆∞·ª£ng' not in df.columns:
        st.warning("Thi·∫øu d·ªØ li·ªáu 'Th·ªùi Gian', 'ƒê√≥ng c·ª≠a' ho·∫∑c 'Kh·ªëi l∆∞·ª£ng' ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã gi√° th·ªã tr∆∞·ªùng.")
        return
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1,
                        subplot_titles=(f'Gi√° ƒë√≥ng c·ª≠a {ticker}', 'Kh·ªëi l∆∞·ª£ng giao d·ªãch'), row_heights=[0.7, 0.3])
    fig.add_trace(go.Scatter(x=df['Th·ªùi Gian'], y=df['ƒê√≥ng c·ª≠a'], name='Gi√° ƒë√≥ng c·ª≠a', line=dict(color='blue')), row=1, col=1)
    df_plot = df.copy()
    df_plot['Volume_Change'] = df_plot['Kh·ªëi l∆∞·ª£ng'].diff()
    colors = []
    for i in range(len(df_plot)):
        if i == 0 or pd.isna(df_plot['Volume_Change'].iloc[i]):
            colors.append('grey')
        elif df_plot['Volume_Change'].iloc[i] > 0:
            colors.append('green')
        elif df_plot['Volume_Change'].iloc[i] < 0:
            colors.append('red')
        else:
            colors.append('grey')
    fig.add_trace(go.Bar(x=df_plot['Th·ªùi Gian'], y=df_plot['Kh·ªëi l∆∞·ª£ng'], name='Kh·ªëi l∆∞·ª£ng', marker_color=colors), row=2, col=1)
    fig.update_layout(title_text=f"Ph√¢n t√≠ch gi√° th·ªã tr∆∞·ªùng c·ªï phi·∫øu: {ticker}", xaxis_rangeslider_visible=False, height=600, legend_title_text='Ch√∫ gi·∫£i')
    fig.update_xaxes(title_text="Th·ªùi Gian", row=2, col=1)
    fig.update_yaxes(title_text="Gi√° (VNƒê)", row=1, col=1)
    fig.update_yaxes(title_text="Kh·ªëi l∆∞·ª£ng", row=2, col=1)
    st.plotly_chart(fig, use_container_width=True)

def plot_recommendations(df_signals, ticker):
    """
    V·∫Ω ƒë·ªì th·ªã gi√° v·ªõi c√°c t√≠n hi·ªáu mua/b√°n.
    """
    if df_signals.empty or 'Th·ªùi Gian' not in df_signals.columns or 'ƒê√≥ng c·ª≠a' not in df_signals.columns:
        st.warning("Thi·∫øu d·ªØ li·ªáu ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã khuy·∫øn ngh·ªã.")
        return
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['ƒê√≥ng c·ª≠a'], name='Gi√° ƒê√≥ng C·ª≠a', line=dict(color='blue')))
    if 'MA20' in df_signals.columns:
        fig.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['MA20'], name='MA20', line=dict(color='orange', dash='dash')))
    if 'MA50' in df_signals.columns:
        fig.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['MA50'], name='MA50', line=dict(color='purple', dash='dash')))
    if 'Buy_Signal_Price' in df_signals.columns:
        fig.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['Buy_Signal_Price'], name='T√≠n hi·ªáu Mua', mode='markers', marker=dict(color='green', size=10, symbol='triangle-up')))
    if 'Sell_Signal_Price' in df_signals.columns:
        fig.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['Sell_Signal_Price'], name='T√≠n hi·ªáu B√°n', mode='markers', marker=dict(color='red', size=10, symbol='triangle-down')))
    fig.update_layout(title_text=f"Khuy·∫øn ngh·ªã Mua/B√°n cho {ticker} (D·ª±a tr√™n ch·ªâ b√°o c∆° b·∫£n)", xaxis_title="Th·ªùi Gian", yaxis_title="Gi√° (VNƒê)", legend_title="Ch√∫ gi·∫£i", height=600)
    st.plotly_chart(fig, use_container_width=True)

    fig_indicators = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, subplot_titles=('RSI (14)', 'MACD'))
    if 'RSI' in df_signals.columns:
        fig_indicators.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['RSI'], name='RSI'), row=1, col=1)
        fig_indicators.add_hline(y=70, line_dash="dash", line_color="red", row=1, col=1, annotation_text="Qu√° mua (70)", annotation_position="bottom right")
        fig_indicators.add_hline(y=30, line_dash="dash", line_color="green", row=1, col=1, annotation_text="Qu√° b√°n (30)", annotation_position="bottom right")
    if 'MACD_line' in df_signals.columns and 'MACD_signal' in df_signals.columns and 'MACD_hist' in df_signals.columns:
        fig_indicators.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['MACD_line'], name='MACD Line', line=dict(color='blue')), row=2, col=1)
        fig_indicators.add_trace(go.Scatter(x=df_signals['Th·ªùi Gian'], y=df_signals['MACD_signal'], name='Signal Line', line=dict(color='orange')), row=2, col=1)
        macd_hist_colors = np.where(df_signals['MACD_hist'] > 0, 'green', 'red')
        fig_indicators.add_trace(go.Bar(x=df_signals['Th·ªùi Gian'], y=df_signals['MACD_hist'], name='MACD Histogram', marker_color=macd_hist_colors), row=2, col=1)
    fig_indicators.update_layout(height=400, legend_title="Ch·ªâ b√°o")
    fig_indicators.update_xaxes(title_text="Th·ªùi Gian", row=2, col=1)
    st.plotly_chart(fig_indicators, use_container_width=True)

def create_sequences(data, n_steps_in, n_steps_out):
    """
    Helper function to create input/output sequences for LSTM.
    """
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix], data[end_ix:out_end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

def predict_price_lstm(df_full, column_to_predict='ƒê√≥ng c·ª≠a', n_steps_in=60, n_steps_out=1, epochs=50, batch_size=32, days_to_predict_future=7):
    """
    D·ª± ƒëo√°n gi√° c·ªï phi·∫øu s·ª≠ d·ª•ng m√¥ h√¨nh LSTM.
    """
    if df_full.empty or column_to_predict not in df_full.columns or len(df_full) < n_steps_in + n_steps_out:
        st.warning(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu '{column_to_predict}' (c·∫ßn √≠t nh·∫•t {n_steps_in + n_steps_out} ng√†y) ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh LSTM.")
        return pd.DataFrame()

    # 0. Set random seed for reproducibility (optional, but good for consistent results during development)
    tf.random.set_seed(42)
    np.random.seed(42)

    # 1. Select and Prepare Data
    data_to_predict = df_full[column_to_predict].values.reshape(-1, 1)

    # 2. Scale Data
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data_to_predict)

    # 3. Create Sequences
    X, y = create_sequences(scaled_data, n_steps_in, n_steps_out)

    if X.shape[0] == 0:
        st.warning(f"Kh√¥ng th·ªÉ t·∫°o ƒë·ªß sequences v·ªõi n_steps_in={n_steps_in}. C·∫ßn th√™m d·ªØ li·ªáu l·ªãch s·ª≠.")
        return pd.DataFrame()

    # 4. Reshape X for LSTM: [samples, timesteps, features]
    X = X.reshape((X.shape[0], X.shape[1], 1)) # 1 feature (gi√° ƒë√≥ng c·ª≠a)

    # 5. Build LSTM Model
    model = Sequential()
    model.add(LSTM(units=100, activation='relu', return_sequences=True, input_shape=(n_steps_in, 1)))
    model.add(Dropout(0.2))
    model.add(LSTM(units=100, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(units=n_steps_out)) # Output layer
    model.compile(optimizer='adam', loss='mean_squared_error')

    # 6. Train Model
    st.write(f"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh LSTM v·ªõi {epochs} epochs...")
    progress_bar = st.progress(0)
    # For simplicity, no explicit train/test split here, training on all available sequences
    # In a real scenario, a validation split or cross-validation would be important.
    history = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0,
                        callbacks=[TrainingProgressCallback(progress_bar, epochs)])
    st.write("Hu·∫•n luy·ªán m√¥ h√¨nh LSTM ho√†n t·∫•t.")

    # 7. Make Future Predictions
    last_sequence = scaled_data[-n_steps_in:] # L·∫•y sequence cu·ªëi c√πng t·ª´ d·ªØ li·ªáu ƒë√£ scale
    current_batch = last_sequence.reshape((1, n_steps_in, 1))
    future_predictions_scaled = []

    for _ in range(days_to_predict_future):
        current_pred = model.predict(current_batch, verbose=0)[0] # D·ª± ƒëo√°n 1 b∆∞·ªõc ti·∫øp theo
        future_predictions_scaled.append(current_pred)
        # C·∫≠p nh·∫≠t current_batch: b·ªè gi√° tr·ªã c≈© nh·∫•t, th√™m gi√° tr·ªã d·ª± ƒëo√°n m·ªõi nh·∫•t
        current_batch = np.append(current_batch[:, 1:, :], [[current_pred]], axis=1)

    # 8. Inverse Transform Predictions
    future_predictions = scaler.inverse_transform(np.array(future_predictions_scaled).reshape(-1,1))

    # 9. Create Prediction DataFrame
    last_date = df_full['Th·ªùi Gian'].iloc[-1]
    future_dates = [last_date + timedelta(days=i) for i in range(1, days_to_predict_future + 1)]

    predictions_df = pd.DataFrame({
        'Th·ªùi Gian D·ª± ƒêo√°n': future_dates,
        'Gi√° D·ª± ƒêo√°n (LSTM)': future_predictions.flatten() # flatten ƒë·ªÉ chuy·ªÉn th√†nh 1D array
    })

    return predictions_df

# Custom Callback for Streamlit Progress Bar
class TrainingProgressCallback(tf.keras.callbacks.Callback):
    def __init__(self, progress_bar, total_epochs):
        super().__init__()
        self.progress_bar = progress_bar
        self.total_epochs = total_epochs

    def on_epoch_end(self, epoch, logs=None):
        self.progress_bar.progress((epoch + 1) / self.total_epochs)


def call_ollama_api(prompt_text):
    """
    G·ª≠i y√™u c·∫ßu ƒë·∫øn Ollama API v√† nh·∫≠n ph·∫£n h·ªìi.
    """
    try:
        payload = {"model": OLLAMA_MODEL, "prompt": prompt_text, "stream": False}
        headers = {'Content-Type': 'application/json'}
        response = requests.post(OLLAMA_API_ENDPOINT, json=payload, headers=headers, timeout=180)
        response.raise_for_status()
        response_data = response.json()
        return response_data.get("response", "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c n·ªôi dung ph·∫£n h·ªìi t·ª´ Ollama.")
    except requests.exceptions.RequestException as e:
        st.error(f"L·ªói k·∫øt n·ªëi ƒë·∫øn Ollama: {e}")
        st.error(f"ƒê·∫£m b·∫£o Ollama ƒëang ch·∫°y t·∫°i {OLLAMA_HOST} v√† model '{OLLAMA_MODEL}' ƒë√£ ƒë∆∞·ª£c pull.")
        st.error(f"Chi ti·∫øt l·ªói: {str(e)}")
        if hasattr(e, 'response') and e.response is not None:
            st.error(f"N·ªôi dung ph·∫£n h·ªìi l·ªói t·ª´ server (n·∫øu c√≥): {e.response.text}")
        return None
    except json.JSONDecodeError:
        st.error("L·ªói gi·∫£i m√£ JSON t·ª´ ph·∫£n h·ªìi c·ªßa Ollama.")
        st.error(f"N·ªôi dung ph·∫£n h·ªìi th√¥: {response.text}")
        return None

def generate_ollama_prompt(ticker, df_with_indicators):
    """
    T·∫°o prompt cho Ollama d·ª±a tr√™n d·ªØ li·ªáu v√† ch·ªâ b√°o.
    """
    if df_with_indicators.empty or 'ƒê√≥ng c·ª≠a' not in df_with_indicators.columns:
        return f"Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu cho c·ªï phi·∫øu {ticker} ƒë·ªÉ ph√¢n t√≠ch."
    latest_data = df_with_indicators.iloc[-1]
    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch k·ªπ thu·∫≠t th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam.
    H√£y ph√¢n t√≠ch chuy√™n s√¢u v·ªÅ c·ªï phi·∫øu {ticker} d·ª±a tr√™n c√°c d·ªØ li·ªáu v√† ch·ªâ b√°o k·ªπ thu·∫≠t g·∫ßn nh·∫•t ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y.

    D·ªØ li·ªáu ng√†y {latest_data.get('Th·ªùi Gian', pd.Timestamp('now')).strftime('%Y-%m-%d')}:
    - Gi√° ƒë√≥ng c·ª≠a: {latest_data.get('ƒê√≥ng c·ª≠a', 'N/A'):,.0f} VNƒê
    - MA5: {latest_data.get('MA5', 'N/A'):,.0f}
    - MA20: {latest_data.get('MA20', 'N/A'):,.0f}
    - MA50: {latest_data.get('MA50', 'N/A'):,.0f}
    - MA200: {latest_data.get('MA200', 'N/A'):,.0f}
    - RSI (14): {latest_data.get('RSI', 'N/A'):.2f}
    - MACD Line: {latest_data.get('MACD_line', 'N/A'):.2f}
    - MACD Signal: {latest_data.get('MACD_signal', 'N/A'):.2f}
    - MACD Histogram: {latest_data.get('MACD_hist', 'N/A'):.2f}
    - Bollinger Bands High: {latest_data.get('BB_high', 'N/A'):,.0f}
    - Bollinger Bands Mid (MA20): {latest_data.get('BB_mid', 'N/A'):,.0f}
    - Bollinger Bands Low: {latest_data.get('BB_low', 'N/A'):,.0f}

    D·ª±a v√†o c√°c th√¥ng tin tr√™n, h√£y cung c·∫•p m·ªôt b√†i ph√¢n t√≠ch chi ti·∫øt bao g·ªìm:
    1.  **ƒê√°nh gi√° xu h∆∞·ªõng hi·ªán t·∫°i:** X√°c ƒë·ªãnh xu h∆∞·ªõng ng·∫Øn h·∫°n v√† trung h·∫°n c·ªßa c·ªï phi·∫øu (tƒÉng, gi·∫£m, ƒëi ngang). Ph√¢n t√≠ch v·ªã tr√≠ c·ªßa gi√° so v·ªõi c√°c ƒë∆∞·ªùng MA quan tr·ªçng (MA20, MA50, MA200).
    2.  **Ph√¢n t√≠ch ch·ªâ b√°o RSI:** ƒê√°nh gi√° m·ª©c ƒë·ªô qu√° mua/qu√° b√°n. RSI ƒëang ·ªü v√πng n√†o v√† c√≥ t√≠n hi·ªáu ph√¢n k·ª≥ n√†o kh√¥ng?
    3.  **Ph√¢n t√≠ch ch·ªâ b√°o MACD:** T√≠n hi·ªáu t·ª´ MACD line, signal line v√† histogram. MACD c√≥ ƒëang cho t√≠n hi·ªáu mua/b√°n hay x√°c nh·∫≠n xu h∆∞·ªõng kh√¥ng?
    4.  **Ph√¢n t√≠ch Bollinger Bands:** Gi√° ƒëang ·ªü v·ªã tr√≠ n√†o so v·ªõi d·∫£i Bollinger? D·∫£i Bollinger ƒëang co th·∫Øt hay m·ªü r·ªông, ƒëi·ªÅu n√†y c√≥ √Ω nghƒ©a g√¨?
    5.  **X√°c ƒë·ªãnh c√°c ng∆∞·ª°ng h·ªó tr·ª£ v√† kh√°ng c·ª±:** D·ª±a tr√™n c√°c ƒë∆∞·ªùng MA, Bollinger Bands, ho·∫∑c c√°c m·ª©c gi√° quan tr·ªçng tr∆∞·ªõc ƒë√≥.
    6.  **Khuy·∫øn ngh·ªã h√†nh ƒë·ªông:** ƒê∆∞a ra m·ªôt khuy·∫øn ngh·ªã c·ª• th·ªÉ (Mua, B√°n, N·∫Øm gi·ªØ, Theo d√µi th√™m) k√®m theo gi·∫£i th√≠ch r√µ r√†ng d·ª±a tr√™n c√°c ph√¢n t√≠ch ·ªü tr√™n. N√™u r√µ c√°c ƒëi·ªÅu ki·ªán ƒë·ªÉ khuy·∫øn ngh·ªã ƒë√≥ c√≤n hi·ªáu l·ª±c ho·∫∑c c·∫ßn xem x√©t l·∫°i.
    7.  **R·ªßi ro ti·ªÅm ·∫©n (n·∫øu c√≥):** D·ª±a tr√™n c√°c ch·ªâ b√°o, c√≥ d·∫•u hi·ªáu r·ªßi ro n√†o c·∫ßn l∆∞u √Ω kh√¥ng?

    H√£y tr√¨nh b√†y b√†i ph√¢n t√≠ch m·ªôt c√°ch chuy√™n nghi·ªáp, r√µ r√†ng, v√† d·ªÖ hi·ªÉu cho nh√† ƒë·∫ßu t∆∞.
    L∆∞u √Ω: ƒê√¢y l√† ph√¢n t√≠ch d·ª±a tr√™n d·ªØ li·ªáu k·ªπ thu·∫≠t v√† kh√¥ng ph·∫£i l√† l·ªùi khuy√™n ƒë·∫ßu t∆∞ t√†i ch√≠nh ƒë∆∞·ª£c c√° nh√¢n h√≥a.
    """
    return prompt

# News Fetching Function (if needed)
def generate_ollama_summary_prompt(news_title, news_content):
    """
    T·∫°o prompt cho Ollama ƒë·ªÉ t√≥m t·∫Øt tin t·ª©c.
    """
    return f"""
    B·∫°n l√† m·ªôt tr·ª£ l√Ω AI c√≥ kh·∫£ nƒÉng t√≥m t·∫Øt tin t·ª©c m·ªôt c√°ch ch√≠nh x√°c v√† ng·∫Øn g·ªçn.
    H√£y t√≥m t·∫Øt nh·ªØng ƒëi·ªÉm ch√≠nh c·ªßa b√†i b√°o sau ƒë√¢y b·∫±ng ti·∫øng Vi·ªát. T·∫≠p trung v√†o th√¥ng tin quan tr·ªçng nh·∫•t li√™n quan ƒë·∫øn c·ªï phi·∫øu ho·∫∑c th·ªã tr∆∞·ªùng.
    ƒê·ªô d√†i t√≥m t·∫Øt kho·∫£ng 3-5 c√¢u.

    Ti√™u ƒë·ªÅ: {news_title}

    N·ªôi dung:
    {news_content}

    T√≥m t·∫Øt:
    """

def fetch_simulated_news(ticker):
    """
    M√¥ ph·ªèng vi·ªác l·∫•y tin t·ª©c. Thay th·∫ø b·∫±ng logic l·∫•y tin th·∫≠t.
    Trong m√¥i tr∆∞·ªùng th·ª±c t·∫ø c√≥ th·ªÉ d√πng tool_code nh∆∞ <tool_code>g.search_news(query=f"tin t·ª©c c·ªï phi·∫øu {ticker} Vi·ªát Nam", limit=5)</tool_code>
    sau ƒë√≥ x·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ.
    """
    st.caption(f"ƒêang m√¥ ph·ªèng vi·ªác l·∫•y tin t·ª©c cho {ticker}... Trong th·ª±c t·∫ø, b·∫°n s·∫Ω d√πng c√¥ng c·ª• t√¨m ki·∫øm ho·∫∑c API tin t·ª©c.")
    current_date = datetime.now()
    news_items = [
        {
            "title": f"Tri·ªÉn v·ªçng t√≠ch c·ª±c cho {ticker} trong qu√Ω t·ªõi sau b√°o c√°o l·ª£i nhu·∫≠n",
            "link": f"https://cafef.vn/{ticker.lower()}-trien-vong-tich-cuc-quy-toi-{current_date.strftime('%Y%m%d')}.chn",
            "snippet": f"C√¥ng ty C·ªï ph·∫ßn {ticker} v·ª´a c√¥ng b·ªë b√°o c√°o t√†i ch√≠nh qu√Ω v·ª´a qua v·ªõi nh·ªØng con s·ªë ·∫•n t∆∞·ª£ng, v∆∞·ª£t k·ª≥ v·ªçng c·ªßa gi·ªõi ph√¢n t√≠ch. Doanh thu tƒÉng tr∆∞·ªüng 25% so v·ªõi c√πng k·ª≥, l·ª£i nhu·∫≠n sau thu·∫ø ƒë·∫°t m·ª©c cao k·ª∑ l·ª•c...",
            "published_date": (current_date - timedelta(days=1)).strftime('%d/%m/%Y'),
            "source": "CafeF"
        },
        {
            "title": f"{ticker} d·ª± ki·∫øn m·ªü r·ªông nh√† m√°y, n√¢ng c√¥ng su·∫•t th√™m 30%",
            "link": f"https://vietstock.vn/{ticker.lower()}-du-kien-mo-rong-nha-may-{current_date.strftime('%Y%m%d')}.htm",
            "snippet": f"Theo th√¥ng tin t·ª´ ƒê·∫°i h·ªôi ƒë·ªìng c·ªï ƒë√¥ng th∆∞·ªùng ni√™n, {ticker} ƒë√£ th√¥ng qua k·∫ø ho·∫°ch ƒë·∫ßu t∆∞ m·ªü r·ªông nh√† m√°y hi·ªán t·∫°i v√† x√¢y d·ª±ng th√™m m·ªôt ph√¢n x∆∞·ªüng m·ªõi. D·ª± ki·∫øn sau khi ho√†n th√†nh, t·ªïng c√¥ng su·∫•t s·∫Ω tƒÉng th√™m 30%, ƒë√°p ·ª©ng nhu c·∫ßu th·ªã tr∆∞·ªùng ƒëang tƒÉng cao.",
            "published_date": (current_date - timedelta(days=3)).strftime('%d/%m/%Y'),
            "source": "Vietstock"
        },
        {
            "title": f"Ph√¢n t√≠ch k·ªπ thu·∫≠t c·ªï phi·∫øu {ticker}: T√≠n hi·ªáu n√†o cho nh√† ƒë·∫ßu t∆∞?",
            "link": f"https://vneconomy.vn/phan-tich-ky-thuat-{ticker.lower()}-tin-hieu-nao-{current_date.strftime('%Y%m%d')}.htm",
            "snippet": f"Sau m·ªôt giai ƒëo·∫°n t√≠ch l≈©y, c·ªï phi·∫øu {ticker} ƒëang cho th·∫•y nh·ªØng d·∫•u hi·ªáu b·ª©t ph√° kh·ªèi v√πng kh√°ng c·ª± quan tr·ªçng. C√°c ch·ªâ b√°o nh∆∞ RSI, MACD ƒë·ªÅu ·ªßng h·ªô xu h∆∞·ªõng tƒÉng gi√° ng·∫Øn h·∫°n. Tuy nhi√™n, nh√† ƒë·∫ßu t∆∞ c·∫ßn ch√∫ √Ω ƒë·∫øn ng∆∞·ª°ng c·∫£n ti·∫øp theo...",
            "published_date": (current_date - timedelta(days=5)).strftime('%d/%m/%Y'),
            "source": "VnEconomy"
        },
         {
            "title": f"C·∫£nh b√°o r·ªßi ro t·ª´ bi·∫øn ƒë·ªông t·ª∑ gi√° c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn {ticker}",
            "link": f"https://baodautu.vn/canh-bao-rui-ro-ty-gia-{ticker.lower()}-{current_date.strftime('%Y%m%d')}.html",
            "snippet": f"M·ªôt s·ªë chuy√™n gia kinh t·∫ø nh·∫≠n ƒë·ªãnh r·∫±ng nh·ªØng bi·∫øn ƒë·ªông g·∫ßn ƒë√¢y tr√™n th·ªã tr∆∞·ªùng ngo·∫°i h·ªëi c√≥ th·ªÉ t·∫°o ra √°p l·ª±c kh√¥ng nh·ªè l√™n c√°c doanh nghi·ªáp c√≥ ho·∫°t ƒë·ªông xu·∫•t nh·∫≠p kh·∫©u l·ªõn nh∆∞ {ticker}. Chi ph√≠ ƒë·∫ßu v√†o c√≥ th·ªÉ tƒÉng n·∫øu kh√¥ng c√≥ bi·ªán ph√°p ph√≤ng ng·ª´a r·ªßi ro t·ª∑ gi√° hi·ªáu qu·∫£.",
            "published_date": (current_date - timedelta(days=2)).strftime('%d/%m/%Y'),
            "source": "B√°o ƒê·∫ßu T∆∞"
        },
        {
            "title": f"B√†i vi·∫øt v·ªÅ {ticker} t·ª´ Fireant.vn",
            "link": f"https://fireant.vn/bai-viet/{ticker.lower()}-*{current_date.strftime('%Y%m%d')}.html",
            "snippet": f"Kh·ªëi ngo·∫°i quay l·∫°i mua r√≤ng c·ªï phi·∫øu {ticker}.",
            "published_date": (current_date - timedelta(days=2)).strftime('%d/%m/%Y'),
            "source": "Fireant"
        }
    ]
    
    return news_items
def to_excel(df):
    """Xu·∫•t DataFrame ra file Excel d·∫°ng bytes."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # ƒê·ªïi t√™n c·ªôt n·∫øu l√† d·ª± ƒëo√°n LSTM
        sheet_name = 'DuDoanGia_LSTM' if 'Gi√° D·ª± ƒêo√°n (LSTM)' in df.columns else 'DuDoanGia'
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    processed_data = output.getvalue()
    return processed_data

# --- Giao di·ªán Streamlit ---
st.set_page_config(layout="wide", page_title="Ph√¢n T√≠ch C·ªï Phi·∫øu", page_icon="üìà")

st.title("üìà C√¥ng C·ª• Ph√¢n T√≠ch C·ªï Phi·∫øu")
st.markdown("Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi c√¥ng c·ª• ph√¢n t√≠ch c·ªï phi·∫øu, s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ `vnstock`, d·ª± ƒëo√°n gi√° b·∫±ng LSTM v√† ph√¢n t√≠ch AI t·ª´ `Ollama`.")

# --- Sidebar ---
st.sidebar.header("‚öôÔ∏è T√πy ch·ªçn Ph√¢n T√≠ch")
stock_ticker = st.sidebar.text_input("Nh·∫≠p m√£ c·ªï phi·∫øu (VD: FPT, HPG):", "FPT").upper()
data_source = st.sidebar.selectbox("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", ["TCBS", "VCI", "SSI", "VND", "DNSE", "VPS"], index=0)
days_to_fetch_sb = st.sidebar.slider("S·ªë ng√†y d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ t·∫£i (cho LSTM v√† ch·ªâ b√°o):", 60, 2000, 730, step=10)
days_for_prediction = st.sidebar.slider("S·ªë ng√†y d·ª± ƒëo√°n gi√° ti·∫øp theo (LSTM):", 1, 30, 7) # Gi·∫£m max cho LSTM
lstm_epochs = st.sidebar.slider("S·ªë epochs hu·∫•n luy·ªán LSTM:", 10, 100, 50, step=10)
lstm_n_steps_in = st.sidebar.slider("S·ªë ng√†y l·ªãch s·ª≠ l√†m ƒë·∫ßu v√†o cho LSTM (lookback window):", 30, 120, 60, step=5)


run_analysis = st.sidebar.button("üöÄ Ch·∫°y Ph√¢n T√≠ch", type="primary", use_container_width=True)

# --- X·ª≠ l√Ω ch√≠nh ---
if run_analysis and stock_ticker:
    with st.spinner(f"ƒêang t·∫£i v√† ph√¢n t√≠ch d·ªØ li·ªáu cho {stock_ticker}..."):
        raw_df = fetch_stock_data(stock_ticker, source=data_source, days_to_fetch=days_to_fetch_sb)

        if raw_df.empty or 'ƒê√≥ng c·ª≠a' not in raw_df.columns:
            st.error(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ho·∫∑c thi·∫øu c·ªôt 'ƒê√≥ng c·ª≠a' cho m√£ {stock_ticker} t·ª´ ngu·ªìn {data_source}.")
        else:
            st.success(f"ƒê√£ t·∫£i th√†nh c√¥ng {len(raw_df)} b·∫£n ghi cho {stock_ticker} (t·ª´ {raw_df['Th·ªùi Gian'].min().strftime('%Y-%m-%d')} ƒë·∫øn {raw_df['Th·ªùi Gian'].max().strftime('%Y-%m-%d')}).")
            df_processed = calculate_technical_indicators(raw_df)
            df_with_signals = generate_signals(df_processed)

            # L·∫•y tin t·ª©c (m√¥ ph·ªèng)
            news_data = fetch_simulated_news(stock_ticker)

            tab1, tab2, tab3, tab4,tab_news = st.tabs([
                "üìä Gi√° Th·ªã Tr∆∞·ªùng",
                "üí° Khuy·∫øn Ngh·ªã (Ch·ªâ b√°o)",
                "üîÆ D·ª± ƒêo√°n Gi√° (LSTM)",
                "ü§ñ AI Ph√¢n T√≠ch (Ollama)",
                "üì∞ Tin T·ª©c & T√≥m T·∫Øt AI"
            ])

            with tab1:
                st.header(f"Gi√° Th·ªã Tr∆∞·ªùng v√† Kh·ªëi L∆∞·ª£ng: {stock_ticker}")
                st.markdown("""...""", unsafe_allow_html=True) # Gi·ªØ nguy√™n m√¥ t·∫£ c≈©
                if not df_processed.empty:
                    plot_market_price(df_processed, stock_ticker)
                else:
                    st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã gi√° th·ªã tr∆∞·ªùng.")

            with tab2:
                st.header(f"Khuy·∫øn Ngh·ªã D·ª±a Tr√™n Ch·ªâ B√°o K·ªπ Thu·∫≠t: {stock_ticker}")
                st.markdown("""...""") # Gi·ªØ nguy√™n m√¥ t·∫£ c≈©
                if not df_with_signals.empty:
                    plot_recommendations(df_with_signals, stock_ticker)
                    st.subheader("D·ªØ li·ªáu ch·ªâ b√°o v√† t√≠n hi·ªáu 10 ng√†y g·∫ßn nh·∫•t:")
                    st.dataframe(df_with_signals[['Th·ªùi Gian', 'ƒê√≥ng c·ª≠a', 'MA5', 'MA20', 'RSI', 'MACD_line', 'MACD_signal', 'Signal']].sort_values(by='Th·ªùi Gian', ascending=False).head(10).set_index('Th·ªùi Gian'))
                else:
                    st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t·∫°o khuy·∫øn ngh·ªã.")

            with tab3:
                st.header(f"D·ª± ƒêo√°n Gi√° C·ªï Phi·∫øu (S·ª≠ d·ª•ng LSTM): {stock_ticker}")
                st.markdown(f"""
                Ph·∫ßn n√†y s·ª≠ d·ª•ng m√¥ h√¨nh **LSTM (Long Short-Term Memory)**, m·ªôt lo·∫°i m·∫°ng n∆°-ron h·ªìi quy (RNN) trong Deep Learning,
                ƒë·ªÉ d·ª± ƒëo√°n gi√° ƒë√≥ng c·ª≠a cho **{days_for_prediction}** ng√†y giao d·ªãch ti·∫øp theo.
                - **C·ª≠a s·ªï nh√¨n l·∫°i (Lookback window):** M√¥ h√¨nh s·ª≠ d·ª•ng d·ªØ li·ªáu c·ªßa **{lstm_n_steps_in}** ng√†y tr∆∞·ªõc ƒë√≥ ƒë·ªÉ d·ª± ƒëo√°n.
                - **S·ªë epochs hu·∫•n luy·ªán:** {lstm_epochs}.
                
                **C·∫¢NH B√ÅO:** D·ª± ƒëo√°n b·∫±ng LSTM ph·ª©c t·∫°p h∆°n v√† c√≥ th·ªÉ cho k·∫øt qu·∫£ t·ªët h∆°n h·ªìi quy tuy·∫øn t√≠nh trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p,
                nh∆∞ng v·∫´n **KH√îNG N√äN** ƒë∆∞·ª£c coi l√† d·ª± b√°o t√†i ch√≠nh tuy·ªát ƒë·ªëi ch√≠nh x√°c. K·∫øt qu·∫£ ph·ª• thu·ªôc nhi·ªÅu v√†o d·ªØ li·ªáu,
                c·∫•u h√¨nh m√¥ h√¨nh v√† qu√° tr√¨nh hu·∫•n luy·ªán. Qu√° tr√¨nh hu·∫•n luy·ªán c√≥ th·ªÉ m·∫•t m·ªôt ch√∫t th·ªùi gian.
                """)

                if not df_processed.empty and len(df_processed) >= lstm_n_steps_in + 1: # C·∫ßn ƒë·ªß d·ªØ li·ªáu cho lookback window + √≠t nh·∫•t 1 ƒëi·ªÉm ƒë·ªÉ d·ª± ƒëo√°n
                    with st.spinner(f"ƒêang chu·∫©n b·ªã d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh LSTM cho {stock_ticker}... (C√≥ th·ªÉ m·∫•t v√†i ph√∫t)"):
                        predictions_df = predict_price_lstm(
                            df_full=df_processed,
                            column_to_predict='ƒê√≥ng c·ª≠a',
                            n_steps_in=lstm_n_steps_in,
                            epochs=lstm_epochs,
                            days_to_predict_future=days_for_prediction
                        )

                    if not predictions_df.empty:
                        st.subheader(f"K·∫øt qu·∫£ d·ª± ƒëo√°n LSTM cho {days_for_prediction} ng√†y t·ªõi:")
                        # ƒê·ªïi t√™n c·ªôt ƒë·ªÉ ph√π h·ª£p v·ªõi logic hi·ªÉn th·ªã v√† xu·∫•t excel
                        predictions_df.rename(columns={'Gi√° D·ª± ƒêo√°n (LSTM)': 'Gi√° D·ª± ƒêo√°n'}, inplace=True)
                        st.dataframe(predictions_df.style.format({"Gi√° D·ª± ƒêo√°n": "{:,.0f} VNƒê"}))

                        fig_pred = go.Figure()
                        fig_pred.add_trace(go.Scatter(x=df_processed['Th·ªùi Gian'], y=df_processed['ƒê√≥ng c·ª≠a'], name='Gi√° L·ªãch S·ª≠', line=dict(color='royalblue')))
                        fig_pred.add_trace(go.Scatter(x=predictions_df['Th·ªùi Gian D·ª± ƒêo√°n'], y=predictions_df['Gi√° D·ª± ƒêo√°n'], name='Gi√° D·ª± ƒêo√°n (LSTM)', line=dict(color='tomato', dash='dash')))
                        fig_pred.update_layout(title=f'D·ª± ƒëo√°n gi√° {stock_ticker} (LSTM)', xaxis_title='Th·ªùi Gian', yaxis_title='Gi√° (VNƒê)')
                        st.plotly_chart(fig_pred, use_container_width=True)

                        excel_data = to_excel(predictions_df)
                        st.download_button(
                            label="üì• T·∫£i xu·ªëng k·∫øt qu·∫£ d·ª± ƒëo√°n LSTM (Excel)",
                            data=excel_data,
                            file_name=f"du_doan_gia_lstm_{stock_ticker}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                    else:
                        st.warning("Kh√¥ng th·ªÉ t·∫°o d·ª± ƒëo√°n LSTM v·ªõi d·ªØ li·ªáu ho·∫∑c c·∫•u h√¨nh hi·ªán t·∫°i.")
                else:
                    st.warning(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ th·ª±c hi·ªán d·ª± ƒëo√°n LSTM (c·∫ßn √≠t nh·∫•t {lstm_n_steps_in + 1} ng√†y d·ªØ li·ªáu c√≥ c·ªôt 'ƒê√≥ng c·ª≠a').")

            with tab4:
                st.header(f"Ph√¢n T√≠ch Chuy√™n S√¢u B·ªüi AI (S·ª≠ d·ª•ng Ollama - {OLLAMA_MODEL}): {stock_ticker}")
                st.markdown(f"""...""") # Gi·ªØ nguy√™n m√¥ t·∫£ c≈©
                if not df_with_signals.empty:
                    with st.spinner(f"ü§ñ AI ({OLLAMA_MODEL}) ƒëang ph√¢n t√≠ch c·ªï phi·∫øu {stock_ticker}..."):
                        prompt = generate_ollama_prompt(stock_ticker, df_with_signals)
                        ai_analysis = ask_ollama(prompt)
                        if ai_analysis:
                            st.subheader("K·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ AI:")
                            st.markdown(ai_analysis)
                        else:
                            st.error(f"Kh√¥ng th·ªÉ nh·∫≠n ph·∫£n h·ªìi t·ª´ Ollama.")
                else:
                    st.warning("Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ch·ªâ b√°o ƒë·ªÉ AI ph√¢n t√≠ch.")
            with tab_news:
                st.header(f"Tin T·ª©c Li√™n Quan ƒê·∫øn {stock_ticker} & T√≥m T·∫Øt AI")
                if news_data:
                    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng tin t·ª©c ƒë·ªÉ tr√°nh qu√° nhi·ªÅu cu·ªôc g·ªçi API t·ªõi Ollama c√πng l√∫c
                    max_news_to_summarize = st.slider("S·ªë l∆∞·ª£ng tin t·ª©c hi·ªÉn th·ªã v√† t√≥m t·∫Øt t·ªëi ƒëa:", 1, len(news_data), min(5, len(news_data)))
                    
                    for i, news_item in enumerate(news_data[:max_news_to_summarize]):
                        st.subheader(f"üì∞ [{news_item['title']}]({news_item['link']})")
                        st.caption(f"Ngu·ªìn: {news_item['source']} - Ng√†y ƒëƒÉng: {news_item['published_date']}")
                        
                        # S·ª≠ d·ª•ng st.expander ƒë·ªÉ ng∆∞·ªùi d√πng c√≥ th·ªÉ xem n·ªôi dung ƒë·∫ßy ƒë·ªß n·∫øu mu·ªën
                        with st.expander("Xem n·ªôi dung g·ªëc (ƒëo·∫°n tr√≠ch)"):
                            st.markdown(news_item['snippet'][:1000] + "..." if len(news_item['snippet']) > 1000 else news_item['snippet']) # Gi·ªõi h·∫°n ƒë·ªô d√†i hi·ªÉn th·ªã

                        # N√∫t ƒë·ªÉ y√™u c·∫ßu t√≥m t·∫Øt (tr√°nh g·ªçi API h√†ng lo·∫°t ngay l√∫c ƒë·∫ßu)
                        # Ho·∫∑c c√≥ th·ªÉ t√≥m t·∫Øt ngay n·∫øu s·ªë l∆∞·ª£ng tin √≠t
                        summary_placeholder = st.empty() # Placeholder ƒë·ªÉ hi·ªÉn th·ªã t√≥m t·∫Øt
                        
                        # T√≥m t·∫Øt ngay
                        with st.spinner(f"AI ({OLLAMA_MODEL}) ƒëang t√≥m t·∫Øt tin '{news_item['title'][:30]}...'"):
                            summary_prompt = generate_ollama_summary_prompt(news_item['title'], news_item['snippet'])
                            # st.text_area("Prompt t√≥m t·∫Øt:", summary_prompt, height=100, key=f"prompt_sum_{i}") # Debug
                            summary = ask_ollama(summary_prompt) # C√≥ th·ªÉ d√πng model kh√°c nh·∫π h∆°n n·∫øu c·∫ßn
                            if summary:
                                summary_placeholder.markdown(f"**üìù T√≥m t·∫Øt AI:**\n{summary}")
                            else:
                                summary_placeholder.warning("Kh√¥ng th·ªÉ t·∫°o t√≥m t·∫Øt cho tin n√†y.")
                        st.divider()
                else:
                    st.info(f"Kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o cho {stock_ticker} (m√¥ ph·ªèng).")
elif run_analysis and not stock_ticker:
    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m√£ c·ªï phi·∫øu v√†o √¥ b√™n tr√°i v√† nh·∫•n 'Ch·∫°y Ph√¢n T√≠ch'.")

st.sidebar.markdown("---")
st.sidebar.info(f"""
    **Th√¥ng tin ·ª©ng d·ª•ng:**
    - **Phi√™n b·∫£n:** 1.2 (14/05/2025) - LSTM Prediction
    - **Ngu·ªìn d·ªØ li·ªáu:** `vnstock`
    - **Ph√¢n t√≠ch AI:** `Ollama` (Model: {OLLAMA_MODEL})
    - **L∆∞u √Ω:** Th√¥ng tin ch·ªâ mang t√≠nh tham kh·∫£o.
""")
st.sidebar.markdown(f"*{datetime.now().strftime('%A, %d/%m/%Y, %H:%M:%S')}*")
